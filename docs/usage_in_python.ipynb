{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507700e8",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb72c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa8692",
   "metadata": {},
   "source": [
    "First of all we need to create cuda extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0080839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/pozdn/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/pozdn/.cache/torch_extensions/py38_cu111/sparse_accumulation_cuda/build.ninja...\n",
      "Building extension module sparse_accumulation_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module sparse_accumulation_cuda...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import cpp_extension\n",
    "\n",
    "cpp_extension.load(\n",
    "    name=\"sparse_accumulation_cuda\",\n",
    "    sources=[\"cuda_optimized/sparse_accumulation_cuda_kernel2D.cu\"],\n",
    "    is_python_module=False,\n",
    "    extra_cuda_cflags=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69963ab",
   "metadata": {},
   "source": [
    "The goal is to compute this for all $\\mu$:\n",
    "\n",
    "$\\text{Output}[:, :, \\mu] = \\sum\\limits_{m_1, m_2} \\text{X_1}[:, :, m_1] * \\text{X_2}[:, :, m_2] * C_{m_1, m_2, \\mu}$\n",
    "\n",
    "This is the subpart of the Clebsch-Gordan iteration for fixed l1, l2, and l. The first two dimensions are the \"dense\" ones, so the same operation is performed for all the indices in the first two dimensions. \n",
    "\n",
    "Since Clebsch-Gordan coefficients are very sparse, it is worthwhile to align them into a 1-dimensional tensor containing only non-zero values, but in this case, we need to supply this tensor with supplementary indices tensors telling us what are the corresponding m1, m2, and $\\mu$ indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d56ce1",
   "metadata": {},
   "source": [
    "Reference slow python implementation is as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d8e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_accumulation_loops(X1, X2, idx_output, output_size, idx_1, idx_2, multipliers):\n",
    "    device = X1.device #all tensors must be on the same device and blah, blah, blah    \n",
    "    dtype = X1.dtype    \n",
    "    \n",
    "    output = torch.zeros([X1.shape[0], X2.shape[1], output_size], device = device,dtype=dtype)\n",
    "    for index in range(idx_output.shape[0]):       \n",
    "        output[:, :, idx_output[index]] += X1[:, :, idx_1[index]] * X2[:, :, idx_2[index]] * multipliers[index]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27d3b2",
   "metadata": {},
   "source": [
    "Here multipliers are the values of Clebsch-Gordan coefficients, idx_1 is the tensor containing corresponding m1 indices, idx_2 is the tensor containing corresponding m2 indices, and idx_output is the tensor containing $\\mu$ indices. output_size is just a single integer, the desired length of the output (2 * l + 1). \n",
    "\n",
    "So the loops go over all the terms, for all $\\mu$, m1, and m2 with non-zero clebsch-gordan coefficients, and the current contribution is added to the output array to the proper place defined by $\\mu$ which is stored in the idx_output\n",
    "\n",
    "The first two dense dimensions are introduced, keeping in mind batch and feature dimensions. If you need just 1, it is possible to introduce a dummy dimension of size 1 ^^. \n",
    "\n",
    "\n",
    "The transformation itself, i.e., Clebsch-Gordan coefficients, can be precomputed once at the very beginning. This repo also contains the code for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d0ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_MAX: \n",
      "multipliers shape:  torch.Size([126])\n",
      "m1_aligned shape:  torch.Size([126])\n",
      "m2_aligned shape:  torch.Size([126])\n",
      "multipliers shape:  torch.Size([126])\n"
     ]
    }
   ],
   "source": [
    "from clebsch_gordan import ClebschGordan, get_real_clebsch_gordan\n",
    "L_MAX = 5\n",
    "clebsch = ClebschGordan(L_MAX).precomputed_\n",
    "indices = get_real_clebsch_gordan(clebsch[L_MAX, L_MAX, L_MAX], L_MAX, L_MAX, L_MAX)\n",
    "\n",
    "m1_aligned, m2_aligned = [], []\n",
    "multipliers, mu_aligned = [], []\n",
    "for mu in range(0, 2 * L_MAX + 1):\n",
    "    for el in indices[mu]:\n",
    "        m1, m2, multiplier = el\n",
    "        m1_aligned.append(m1)\n",
    "        m2_aligned.append(m2)\n",
    "        multipliers.append(multiplier)\n",
    "        mu_aligned.append(mu)\n",
    "m1_aligned = torch.LongTensor(m1_aligned)\n",
    "m2_aligned = torch.LongTensor(m2_aligned)\n",
    "mu_aligned = torch.LongTensor(mu_aligned)\n",
    "multipliers = torch.FloatTensor(multipliers)\n",
    "\n",
    "indices = np.argsort(mu_aligned)\n",
    "\n",
    "m1_aligned = m1_aligned[indices].cuda()\n",
    "m2_aligned = m2_aligned[indices].cuda()\n",
    "mu_aligned = mu_aligned[indices].cuda()\n",
    "multipliers = multipliers[indices].cuda()\n",
    "\n",
    "print(\"L_MAX: \")\n",
    "print(\"multipliers shape: \", multipliers.shape)\n",
    "print(\"m1_aligned shape: \", m1_aligned.shape)\n",
    "print(\"m2_aligned shape: \", m2_aligned.shape)\n",
    "print(\"multipliers shape: \", multipliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15db4ef",
   "metadata": {},
   "source": [
    "This is a simple wrapper on sympy package, and the definition of the real clebsch-gordan coefficients is consistent with librascal real spherical harmonics, nice, wigner iterations, and rascaline\n",
    "\n",
    "Now we can do the Clebsch-Gordan iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee0c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 17, 11])\n"
     ]
    }
   ],
   "source": [
    "X1 = torch.randn(100, 17, 2 * L_MAX + 1).cuda()\n",
    "X2 = torch.randn(100, 17, 2 * L_MAX + 1).cuda()\n",
    "\n",
    "output_loops = sparse_accumulation_loops(X1, X2, mu_aligned, 2 * L_MAX + 1, m1_aligned, m2_aligned, multipliers)\n",
    "print(output_loops.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017dfc4e",
   "metadata": {},
   "source": [
    "The main contribution of this package is the very optimized cuda (and cpu) implementation of this operation which can be invoked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c50964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 17, 11])\n"
     ]
    }
   ],
   "source": [
    "output_fast = torch.ops.sparse_accumulation_cuda.forward(X1, X2, mu_aligned, 2 * L_MAX + 1, m1_aligned, m2_aligned, multipliers)[0]\n",
    "print(output_fast.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa68890",
   "metadata": {},
   "source": [
    "outputs are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5deced68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9605e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(torch.abs(output_loops - output_fast)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d475e",
   "metadata": {},
   "source": [
    "You can take a look at the benchmarks files .py along with their output .out to get an idea 1) how to benchmark this properly with gpu synchronization and the speed of this operation compared to a naive implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8c1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
