{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507700e8",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e8e17",
   "metadata": {},
   "source": [
    "[Understood that there is no sense to update tutorial further until certain code development]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb72c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9059993",
   "metadata": {},
   "source": [
    "## preparing the dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e5b89",
   "metadata": {},
   "source": [
    "Let's prepare some dummy data to play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedcfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.randn(10, 17, 3)\n",
    "X2 = torch.randn(10, 17, 4)\n",
    "\n",
    "m1 = torch.LongTensor([0, 1, 1, 2])\n",
    "m2 = torch.LongTensor([0, 0, 3, 1])\n",
    "mu = torch.LongTensor([0, 3, 1, 2])\n",
    "\n",
    "C = torch.FloatTensor([0.17, 0.23, 0.4, -0.9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480604ea",
   "metadata": {},
   "source": [
    "## sparse accumulation cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbe0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76afaeae",
   "metadata": {},
   "source": [
    "## sparse accumulation gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da26cc",
   "metadata": {},
   "source": [
    "First of all we need to compile the extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f5caec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /home/pozdn/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/pozdn/.cache/torch_extensions/py39_cu113/sparse_accumulation_cuda/build.ninja...\n",
      "Building extension module sparse_accumulation_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module sparse_accumulation_cuda...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import cpp_extension\n",
    "\n",
    "cpp_extension.load(\n",
    "    name=\"sparse_accumulation_cuda\",\n",
    "    sources=[\"cuda_optimized/sparse_accumulation_cuda_kernel2D.cu\"],\n",
    "    is_python_module=False,\n",
    "    extra_cuda_cflags=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ebc863",
   "metadata": {},
   "source": [
    "Let's move our dummy data to the gpu:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ff70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_cuda = X1.cuda()\n",
    "X2_cuda = X2.cuda()\n",
    "m1_cuda = m1.cuda()\n",
    "m2_cuda = m2.cuda()\n",
    "mu_cuda = mu.cuda()\n",
    "C_cuda = C.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b646ba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 17, 5])\n"
     ]
    }
   ],
   "source": [
    "output = torch.ops.sparse_accumulation_cuda.forward(X1_cuda, X2_cuda, mu_cuda, 5, m1_cuda, m2_cuda, C_cuda)[0]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d4700",
   "metadata": {},
   "source": [
    "## Precomputing transformation rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89ad82",
   "metadata": {},
   "source": [
    "If we want the sparse accumulation operation to do the actual Clebsch-Gordan iteration we need to precompute the corresponding transformation rule and populate the arrays ``m1``, ``m2``, ``mu`` and ``multipliers`` with the actual Clebsch-Gordan coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97342a",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69963ab",
   "metadata": {},
   "source": [
    "The goal is to compute this for all $\\mu$:\n",
    "\n",
    "$\\text{Output}[:, :, \\mu] = \\sum\\limits_{m_1, m_2} \\text{X_1}[:, :, m_1] * \\text{X_2}[:, :, m_2] * C_{m_1, m_2, \\mu}$\n",
    "\n",
    "This is the subpart of the Clebsch-Gordan iteration for fixed l1, l2, and l. The first two dimensions are the \"dense\" ones, so the same operation is performed for all the indices in the first two dimensions. \n",
    "\n",
    "Since Clebsch-Gordan coefficients are very sparse, it is worthwhile to align them into a 1-dimensional tensor containing only non-zero values, but in this case, we need to supply this tensor with supplementary indices tensors telling us what are the corresponding m1, m2, and $\\mu$ indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02827f7",
   "metadata": {},
   "source": [
    "## Reference slow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d56ce1",
   "metadata": {},
   "source": [
    "Reference slow python implementation is as simple as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d8e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_accumulation_loops(X1, X2, idx_output, output_size, idx_1, idx_2, multipliers):\n",
    "    device = X1.device #all tensors must be on the same device and blah, blah, blah    \n",
    "    dtype = X1.dtype    \n",
    "    \n",
    "    output = torch.zeros([X1.shape[0], X2.shape[1], output_size], device = device,dtype=dtype)\n",
    "    for index in range(idx_output.shape[0]):       \n",
    "        output[:, :, idx_output[index]] += X1[:, :, idx_1[index]] * X2[:, :, idx_2[index]] * multipliers[index]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27d3b2",
   "metadata": {},
   "source": [
    "Here multipliers are the values of Clebsch-Gordan coefficients, idx_1 is the tensor containing corresponding m1 indices, idx_2 is the tensor containing corresponding m2 indices, and idx_output is the tensor containing $\\mu$ indices. output_size is just a single integer, the desired length of the output (2 * l + 1). \n",
    "\n",
    "So the loops go over all the terms, for all $\\mu$, m1, and m2 with non-zero clebsch-gordan coefficients, and the current contribution is added to the output array to the proper place defined by $\\mu$ which is stored in the idx_output\n",
    "\n",
    "The first two dense dimensions are introduced, keeping in mind batch and feature dimensions. If you need just 1, it is possible to introduce a dummy dimension of size 1 ^^. \n",
    "\n",
    "\n",
    "The transformation itself, i.e., Clebsch-Gordan coefficients, can be precomputed once at the very beginning. This repo among the other things contains the code for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d0ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_MAX: \n",
      "multipliers shape:  torch.Size([126])\n",
      "m1_aligned shape:  torch.Size([126])\n",
      "m2_aligned shape:  torch.Size([126])\n",
      "multipliers shape:  torch.Size([126])\n"
     ]
    }
   ],
   "source": [
    "from clebsch_gordan import ClebschGordan, get_real_clebsch_gordan\n",
    "L_MAX = 5\n",
    "clebsch = ClebschGordan(L_MAX).precomputed_\n",
    "indices = get_real_clebsch_gordan(clebsch[L_MAX, L_MAX, L_MAX], L_MAX, L_MAX, L_MAX)\n",
    "\n",
    "m1_aligned, m2_aligned = [], []\n",
    "multipliers, mu_aligned = [], []\n",
    "for mu in range(0, 2 * L_MAX + 1):\n",
    "    for el in indices[mu]:\n",
    "        m1, m2, multiplier = el\n",
    "        m1_aligned.append(m1)\n",
    "        m2_aligned.append(m2)\n",
    "        multipliers.append(multiplier)\n",
    "        mu_aligned.append(mu)\n",
    "m1_aligned = torch.LongTensor(m1_aligned)\n",
    "m2_aligned = torch.LongTensor(m2_aligned)\n",
    "mu_aligned = torch.LongTensor(mu_aligned)\n",
    "multipliers = torch.FloatTensor(multipliers)\n",
    "\n",
    "indices = np.argsort(mu_aligned)\n",
    "\n",
    "m1_aligned = m1_aligned[indices].cuda()\n",
    "m2_aligned = m2_aligned[indices].cuda()\n",
    "mu_aligned = mu_aligned[indices].cuda()\n",
    "multipliers = multipliers[indices].cuda()\n",
    "\n",
    "print(\"L_MAX: \")\n",
    "print(\"multipliers shape: \", multipliers.shape)\n",
    "print(\"m1_aligned shape: \", m1_aligned.shape)\n",
    "print(\"m2_aligned shape: \", m2_aligned.shape)\n",
    "print(\"multipliers shape: \", multipliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15db4ef",
   "metadata": {},
   "source": [
    "This is a simple wrapper on sympy package, and the definition of the real clebsch-gordan coefficients is consistent with librascal real spherical harmonics, nice, wigner iterations, and rascaline\n",
    "\n",
    "Now we can do the Clebsch-Gordan iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee0c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 17, 11])\n"
     ]
    }
   ],
   "source": [
    "X1 = torch.randn(100, 17, 2 * L_MAX + 1).cuda()\n",
    "X2 = torch.randn(100, 17, 2 * L_MAX + 1).cuda()\n",
    "\n",
    "output_loops = sparse_accumulation_loops(X1, X2, mu_aligned, 2 * L_MAX + 1, m1_aligned, m2_aligned, multipliers)\n",
    "print(output_loops.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8090fd",
   "metadata": {},
   "source": [
    "## Fast implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017dfc4e",
   "metadata": {},
   "source": [
    "The main contribution of this package is the very optimized cuda (and cpu) implementation of this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa8692",
   "metadata": {},
   "source": [
    "First of all we need to create cuda extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0080839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4885853",
   "metadata": {},
   "source": [
    "Next the fast implementation can be invoked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c50964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa68890",
   "metadata": {},
   "source": [
    "outputs are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5deced68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_fast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mabs(output_loops \u001b[38;5;241m-\u001b[39m \u001b[43moutput_fast\u001b[49m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_fast' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.max(torch.abs(output_loops - output_fast)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d475e",
   "metadata": {},
   "source": [
    "You can take a look at the benchmarks files .py along with their output .out to get an idea 1) how to benchmark this properly with gpu synchronization and 2) the speed of this operation compared to a naive implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8c1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
